Below are **detailed, exam-oriented notes** for **SEBI Grade A â€“ Information Technology (IT) Stream** covering the requested topics from Algorithms and Data Structures.
Iâ€™ve structured them to be crisp yet comprehensive, suitable for revision and answer writing.

---

# ðŸ“˜ **ALGORITHMS FOR PROBLEM SOLVING â€” DETAILED NOTES**

---

# **1. Tree and Graph Traversals**

## **A. Tree Traversals**

### **1. Depth First Traversal (DFT) / DFS for Trees**

Three standard variants:

#### **(i) Pre-order (Root â†’ Left â†’ Right)**

* Visit root
* Traverse left subtree
* Traverse right subtree
  **Applications:** Prefix expressions, copying a tree.

#### **(ii) In-order (Left â†’ Root â†’ Right)**

* Visit left subtree â†’ root â†’ right subtree
  **Applications:** Gets sorted order of elements in a Binary Search Tree (BST).

#### **(iii) Post-order (Left â†’ Right â†’ Root)**

**Applications:** Deleting/freeing nodes, postfix expressions, evaluating expressions.

---

## **B. Graph Traversals**

Graphs may be:

* Directed/undirected
* Weighted/unweighted
* Represented using adjacency matrix/list

### **1. Breadth-First Search (BFS)**

* Uses a **queue**
* Visits all neighbours at current level before moving deeper
  **Time:** O(V + E)
  **Applications:**
* Shortest path in unweighted graphs
* Level order traversal
* Checking bipartiteness

### **2. Depth-First Search (DFS)**

* Uses explicit stack or recursion
  **Time:** O(V + E)
  **Applications:**
* Topological sorting
* Detecting cycles
* Finding connected components
* Solving maze/backtracking problems

---

# **2. Connected Components**

A **connected component** of an undirected graph is a maximal set of vertices where each pair is reachable.

### **Finding CCs**

Using BFS or DFS:

1. Initialize visited[]
2. For every unvisited node, start DFS/BFS â†’ this forms one connected component

**Time:** O(V + E)

### **Applications:**

* Image segmentation
* Clustering
* Detecting isolated network regions
* Social network analysis

### For directed graphs:

* **Strongly Connected Components (SCCs)**
  Use **Kosarajuâ€™s Algorithm** or **Tarjanâ€™s Algorithm**

---

# **3. Spanning Trees**

A **Spanning Tree (ST)** of a connected undirected graph:

* Subset of edges
* Connects all vertices
* Contains **(V â€“ 1)** edges
* No cycles

## **Minimum Spanning Tree (MST)**

Finds the spanning tree with minimum total edge weight.

### **Algorithms to find MST**

### **1. Kruskalâ€™s Algorithm**

* Greedy
* Sort edges by weight
* Pick smallest edges without forming cycles (use Union-Find DSU)
  **Time:** O(E log E)

### **2. Primâ€™s Algorithm**

* Start from any node
* Grow MST by adding nearest node using priority queue (min-heap)
  **Time:** O(E log V)

---

# **4. Shortest Paths**

### **A. Single-Source Shortest Path (SSSP)**

### **1. Dijkstraâ€™s Algorithm**

* For weighted graphs with **non-negative weights**
* Uses priority queue
  **Time:** O(E log V)

### **2. Bellman-Ford Algorithm**

* Works with **negative** weights
  **Time:** O(V Ã— E)
  **Detects negative cycles**

### **B. All-Pairs Shortest Path (APSP)**

### **1. Floyd-Warshall Algorithm**

* Dynamic Programming
  **Time:** O(VÂ³)

### **C. Shortest Path in Unweighted Graph**

Use **BFS**
**Time:** O(V + E)

---

# **5. Hashing**

Hashing is used for fast insert/search/delete operations.

### **Key Concepts**

* **Hash function:** h(x) â†’ index
* **Load factor (Î±):** n / table_size

### **Collision Handling Techniques**

### **1. Open Addressing**

* **Linear probing:** (h(x) + i) mod m
  *Pros:* Simple
  *Cons:* Primary clustering
* **Quadratic probing:** (h(x) + iÂ²) mod m
* **Double hashing:** h1(x) + i Ã— h2(x)
  *Best clustering avoidance*

### **2. Separate Chaining**

* Each bucket has a linked list of colliding keys

**Applications:** Hash tables, symbol tables, sets/dictionaries, indexing

---

# **6. Sorting Algorithms**

| Algorithm      | Time (Best/Average/Worst) | Space    | Stable | Notes                       |
| -------------- | ------------------------- | -------- | ------ | --------------------------- |
| Bubble Sort    | O(n)/O(nÂ²)/O(nÂ²)          | O(1)     | Yes    | Simple, slow                |
| Selection Sort | O(nÂ²)/O(nÂ²)/O(nÂ²)         | O(1)     | No     | Minimum selection           |
| Insertion Sort | O(n)/O(nÂ²)/O(nÂ²)          | O(1)     | Yes    | Good for nearly sorted data |
| Merge Sort     | O(n log n)                | O(n)     | Yes    | Divide & conquer            |
| Quick Sort     | O(n log n)/O(nÂ²)          | O(log n) | No     | Fastest in practice         |
| Heap Sort      | O(n log n)                | O(1)     | No     | Uses heap data structure    |

### **Key Points**

* **Merge sort** is stable and good for linked lists.
* **Quick sort** is good for arrays, but worst case occurs when pivot is always smallest/largest.
* **Heap sort** maintains a binary heap.

---

# **7. Searching Algorithms**

### **1. Linear Search**

* Check all elements
  **Time:** O(n)
  **Use:** Small or unsorted lists

### **2. Binary Search**

* Requires sorted array
  **Time:** O(log n)

Variants:

* First/last occurrence
* Count of occurrences
* Lower bound / upper bound

### **3. Search in BST**

* Average: O(log n)
* Worst: O(n) (when skewed)

---

# **8. Algorithm Design Techniques**

---

## **A. Greedy Algorithms**

Make locally optimal choice at each step hoping for global optimum.

### **Characteristics**

* Greedy choice property
* Optimal substructure

### **Examples:**

* Kruskalâ€™s MST
* Primâ€™s MST
* Dijkstra's algorithm
* Fractional Knapsack
* Job sequencing with deadlines
* Huffman coding

---

## **B. Dynamic Programming (DP)**

Breaks problem into overlapping subproblems; uses memoization or tabulation.

### **Characteristics**

* Optimal substructure
* Overlapping subproblems

### **Techniques**

* **Top-down (Memoization)**
* **Bottom-up (Tabulation)**

### **Examples**

* Fibonacci DP
* 0/1 Knapsack
* Longest Common Subsequence (LCS)
* Matrix chain multiplication
* Floyd-Warshall

---

## **C. Divide and Conquer**

Divide â†’ Solve recursively â†’ Combine

### **Examples**

* Merge sort
* Quick sort
* Binary search
* Maximum subarray sum (Kadane/Divide-Conquer)
* Fast Fourier Transform (FFT)

**Time Complexity Often:** T(n) = 2T(n/2) + O(n)

---

Absolutely! Iâ€™ll create **SEBI Grade A-style MCQs** covering the topics you requested (Algorithms, Trees, Graphs, Hashing, Sorting, Searching, and Design Techniques). Iâ€™ll provide **10 questions** followed by **answers at the end**. These will mimic the pattern of SEBI IT stream exams.

---

# **SEBI Grade A â€“ IT Stream: Practice MCQs**

---

### **1. Which of the following tree traversals will give nodes of a Binary Search Tree in ascending order?**

A) Pre-order
B) In-order
C) Post-order
D) Level-order

---

### **2. In a connected undirected graph with V vertices, how many edges does any spanning tree have?**

A) V
B) V â€“ 1
C) V + 1
D) 2V â€“ 1

---

### **3. Which algorithm is suitable for finding the shortest path from a single source to all other vertices in a graph with negative weight edges but no negative cycles?**

A) Dijkstra
B) Bellman-Ford
C) Prim
D) Kruskal

---

### **4. Consider the following edges of a graph with weights:**

Edges: (A-B: 1), (A-C: 3), (B-C: 2), (B-D: 4), (C-D: 5)

**Which edge will Kruskalâ€™s algorithm select first while forming the MST?**

A) A-C
B) A-B
C) B-C
D) B-D

---

### **5. Which hashing technique can suffer from primary clustering?**

A) Linear probing
B) Quadratic probing
C) Double hashing
D) Separate chaining

---

### **6. The time complexity of merge sort in the worst case is:**

A) O(nÂ²)
B) O(n log n)
C) O(n)
D) O(log n)

---

### **7. Which of the following algorithms uses the greedy technique?**

A) Longest Common Subsequence
B) 0/1 Knapsack
C) Fractional Knapsack
D) Matrix Chain Multiplication

---

### **8. In binary search, the worst-case number of comparisons for an array of size n is:**

A) O(n)
B) O(log n)
C) O(n log n)
D) O(1)

---

### **9. Which of the following statements about DFS and BFS is correct?**

A) DFS uses a queue, BFS uses a stack
B) BFS can find shortest path in weighted graph
C) BFS uses a queue, DFS uses a stack
D) DFS is always better than BFS

---

### **10. Which dynamic programming problem is **not** typically solved using DP?**

A) Fibonacci numbers
B) Longest Common Subsequence
C) Fractional Knapsack
D) 0/1 Knapsack

---

# **Answer Key**

1. **B** â€“ In-order traversal of BST gives sorted order.
2. **B** â€“ Any spanning tree has V â€“ 1 edges.
3. **B** â€“ Bellman-Ford works for graphs with negative weights (no negative cycles).
4. **B** â€“ Kruskal picks edge with least weight first â†’ A-B (weight 1).
5. **A** â€“ Linear probing suffers from primary clustering.
6. **B** â€“ Merge sort worst-case: O(n log n).
7. **C** â€“ Fractional Knapsack is solved by greedy.
8. **B** â€“ Binary search worst-case: O(log n).
9. **C** â€“ BFS uses queue; DFS uses stack (or recursion).
10. **C** â€“ Fractional Knapsack uses greedy, not DP.

---
