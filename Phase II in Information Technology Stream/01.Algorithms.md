
---

# üìò **ALGORITHMS ‚Äî Detailed Notes for SEBI Grade A IT (Phase II)**

---

# 1Ô∏è‚É£ **Sorting Algorithms**

Sorting algorithms arrange data in a specific order (ascending/descending). Key parameters:
‚úî Time Complexity
‚úî Space Complexity
‚úî Stability
‚úî In-place vs Out-of-place sorting

---

## **1. Bubble Sort**

* **Idea:** Repeatedly swap adjacent elements if they are in the wrong order.
* **Time Complexity:**

  * Worst/Average: **O(n¬≤)**
  * Best (already sorted): **O(n)**
* **Space:** O(1)
* **Stable:** Yes
* **Use Case:** Rare in industry; useful for teaching.

---

## **2. Selection Sort**

* **Idea:** Repeatedly find the minimum element and place it at the beginning.
* **Time:** O(n¬≤) in all cases
* **Space:** O(1)
* **Stable:** No
* **Use Case:** When memory writes are costly (minimum swaps).

---

## **3. Insertion Sort**

* **Idea:** Insert each element into its correct position in a sorted subarray.
* **Time:**

  * Worst/Average: O(n¬≤)
  * Best: O(n)
* **Space:** O(1)
* **Stable:** Yes
* **Use Case:** Good for small or nearly sorted inputs.

---

## **4. Merge Sort**

* **Technique:** Divide and Conquer
* **Time:**

  * Worst/Average/Best: **O(n log n)**
* **Space:** O(n) (not in-place)
* **Stable:** Yes
* **Use Case:** External sorting, linked lists.

---

## **5. Quick Sort**

* **Technique:** Divide and Conquer
* **Idea:** Choose pivot ‚Üí partition ‚Üí recursively sort subarrays.
* **Time:**

  * Worst: O(n¬≤) (rare; occurs on sorted arrays w/ bad pivot)
  * Average/Best: O(n log n)
* **Space:** O(log n) recursion
* **Stable:** No
* **Use Case:** General-purpose fast sorting.

---

## **6. Heap Sort**

* **Technique:** Use Max-Heap
* **Time:**

  * O(n log n) always
* **Space:** O(1)
* **Stable:** No
* **Use Case:** When memory is limited; widely used.

---

## **7. Counting Sort (Non-comparison)**

* **Idea:** Count frequency of each distinct value.
* **Time:** O(n + k)
* **Space:** O(k)
* **Stable:** Yes
* **Use Case:** Limited range integers.

---

## **8. Radix Sort (Non-comparison)**

* **Idea:** Sort digits place-wise (LSD or MSD).
* **Time:** O(d * (n+k))
* **Space:** O(n + k)
* **Use Case:** Sorting large numbers/IDs/strings.

---

# 2Ô∏è‚É£ **Searching Algorithms**

---

## **1. Linear Search**

* **Idea:** Scan elements sequentially.
* **Time:**

  * Best: O(1)
  * Worst: O(n)
* **Use:** Small/unsorted datasets.

---

## **2. Binary Search**

* **Requirement:** Input must be sorted.
* **Idea:** Repeatedly divide search interval in half.
* **Time:** O(log n)
* **Space:** O(1)
* **Use:** Searching large datasets.

Binary Search Variants:

* First occurrence
* Last occurrence
* Count occurrences
* Search in rotated sorted array

---

# 3Ô∏è‚É£ **Greedy Algorithms**

Greedy chooses the best possible choice at each step.
‚úî No backtracking
‚úî Optimal for specific problems only
‚úî Uses **Greedy Choice Property** + **Optimal Substructure**

---

## **Common Greedy Problems**

### **1. Activity Selection Problem**

* Select max number of non-overlapping activities.
* Sort by **finish time** and pick earliest.

### **2. Fractional Knapsack**

* Pick items by **value/weight ratio** until capacity is full.
* **Optimal** for fractional case.

### **3. Huffman Coding**

* Optimal prefix-free encoding based on frequency.
* Build min-heap ‚Üí combine smallest two ‚Üí repeat.

### **4. Minimum Spanning Tree**

* **Kruskal‚Äôs Algorithm:** Sort edges ‚Üí add if no cycle (Union-Find).
* **Prim‚Äôs Algorithm:** Grow tree from one node.

### **5. Dijkstra‚Äôs Algorithm**

* Shortest path from source with **non-negative edges**.
* Uses Min-Heap.

---

# 4Ô∏è‚É£ **Dynamic Programming (DP)**

DP = Recursion + Memoization / Tabulation
Uses **Optimal Substructure** and **Overlapping Subproblems**

---

## **Approaches**

### 1. **Top-Down (Memoization)**

Recursive + caching results.

### 2. **Bottom-Up (Tabulation)**

Iterative table building.

---

## **Common DP Problems**

### **1. Fibonacci / DP basics**

* Top-Down: O(n)
* Bottom-Up: O(n)

### **2. 0/1 Knapsack**

* Cannot take fractions.
* DP recurrence:
  `dp[i][w] = max(dp[i‚àí1][w], value + dp[i‚àí1][w ‚àí weight])`

### **3. Longest Common Subsequence (LCS)**

* Recurrence:
  If match: `1 + dp[i‚àí1][j‚àí1]`
  Else: `max(dp[i‚àí1][j], dp[i][j‚àí1])`

### **4. Matrix Chain Multiplication**

* Parenthesization for min cost.

### **5. Coin Change**

* Min coins OR number of ways.

### **6. Edit Distance (Levenshtein)**

* Insert, Delete, Replace.

### **7. LIS (Longest Increasing Subsequence)**

* DP: O(n¬≤)
* Binary search optimization: O(n log n)

---

# 5Ô∏è‚É£ **Backtracking**

Backtracking = DFS + pruning
‚úî Tries possibilities
‚úî Backtracks on failure
‚úî Used where greedy/DP fails

---

## **Common Backtracking Problems**

### **1. N-Queens Problem**

* Place queens so none attack.
* Use row by row placement.

### **2. Sudoku Solver**

* Fill empty cells using safe placements.

### **3. Subsets / Permutations**

* Generate power sets.

### **4. Rat in a Maze**

* Try paths recursively.

### **5. Graph Coloring**

* Assign colors without conflicts.

Backtracking Time Complexity is often **O(b^d)** (exponential).

---

# 6Ô∏è‚É£ **Divide and Conquer**

Divide ‚Üí Solve ‚Üí Combine
‚úî Efficient for recursive subproblems
‚úî Used in many core algorithms

---

## **Key Algorithms**

### **1. Merge Sort**

* Divide array ‚Üí merge sorted halves.

### **2. Quick Sort**

* Partition around pivot.

### **3. Binary Search**

* Divide search space.

### **4. Closest Pair of Points**

* Solve using geometric partitioning.

### **5. Fast Fourier Transform (FFT)**

Used for signal processing + convolution.

### **6. Karatsuba Multiplication**

* Fast integer multiplication.

---

# 7Ô∏è‚É£ **Pattern Searching Algorithms**

Used for finding substrings in a text.

---

## **1. Na√Øve Pattern Search**

* Check for match at every index.
* Time: O(n * m)

---

## **2. KMP Algorithm (Knuth-Morris-Pratt)**

* Uses **LPS (Longest Prefix Suffix)** array to skip unnecessary comparisons.
* Time: O(n + m)
* Excellent for repeated pattern searching.

---

## **3. Rabin-Karp**

* Uses hashing for pattern comparison.
* Average: O(n + m)
* Worst: O(nm) when hash collisions occur.
* Best use: multiple pattern matching (plagiarism detection).

---

## **4. Boyer-Moore Algorithm**

* Skips characters by matching from right to left.
* Uses:

  * **Bad Character Rule**
  * **Good Suffix Rule**
* Excellent for large alphabets (text search engines).

---

## **5. Z-Algorithm**

* Preprocess pattern + text into Z-array.
* Time: O(n + m)
* Efficient for substring search and pattern preprocessing.

---
